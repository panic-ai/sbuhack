{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aniru\\OneDrive\\Desktop\\sbuhack\\sbu\\Lib\\site-packages\\transformers\\models\\yolos\\feature_extraction_yolos.py:38: FutureWarning: The class YolosFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use YolosImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from transformers import YolosFeatureExtractor, YolosForObjectDetection\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import json\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key='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')\n",
    "\n",
    "\n",
    "cats = ['shirt, blouse', 'top, t-shirt, sweatshirt', 'sweater', 'cardigan', 'jacket', 'vest', 'pants', 'shorts', 'skirt', 'coat', 'dress', 'jumpsuit', 'cape', 'glasses', 'hat', 'headband, head covering, hair accessory', 'tie', 'glove', 'watch', 'belt', 'leg warmer', 'tights, stockings', 'sock', 'shoe', 'bag, wallet', 'scarf', 'umbrella', 'hood', 'collar', 'lapel', 'epaulette', 'sleeve', 'pocket', 'neckline', 'buckle', 'zipper', 'applique', 'bead', 'bow', 'flower', 'fringe', 'ribbon', 'rivet', 'ruffle', 'sequin', 'tassel']\n",
    "\n",
    "\n",
    "def fix_channels(t):\n",
    "    \"\"\"\n",
    "    Some images may have 4 channels (transparent images) or just 1 channel (black and white images), in order to let the images have only 3 channels. I am going to remove the fourth channel in transparent images and stack the single channel in back and white images.\n",
    "    :param t: Tensor-like image\n",
    "    :return: Tensor-like image with three channels\n",
    "    \"\"\"\n",
    "    if len(t.shape) == 2:\n",
    "        return ToPILImage()(torch.stack([t for i in (0, 0, 0)]))\n",
    "    if t.shape[0] == 4:\n",
    "        return ToPILImage()(t[:3])\n",
    "    if t.shape[0] == 1:\n",
    "        return ToPILImage()(torch.stack([t[0] for i in (0, 0, 0)]))\n",
    "    return ToPILImage()(t)\n",
    "\n",
    "def idx_to_text(i):\n",
    "    return cats[i]\n",
    "\n",
    "def get_dominant_color(image, num_clusters=13):\n",
    "    # Resize image to speed up processing\n",
    "    small_image = image.resize((50, 50))\n",
    "    # Convert image data to a sequence of pixels\n",
    "    np_image = np.array(small_image)\n",
    "    np_image = np_image.reshape((np_image.shape[0] * np_image.shape[1], 3))\n",
    "    # Find clusters of colors\n",
    "    clusters = KMeans(n_clusters=num_clusters).fit(np_image)\n",
    "    # Count labels to find the most common cluster\n",
    "    counts = Counter(clusters.labels_)\n",
    "    # Find the most common cluster center\n",
    "    center = clusters.cluster_centers_[counts.most_common(1)[0][0]]\n",
    "    return tuple(center.astype(int))\n",
    "\n",
    "def rgb_to_color_name(rgb):\n",
    "    # Define your color mapping\n",
    "    colors = {\n",
    "        'red': (255, 0, 0),\n",
    "        'brown': (165, 42, 42),\n",
    "        'orange': (255, 165, 0),\n",
    "        'yellow': (255, 255, 0),\n",
    "        'pink': (255, 192, 203),\n",
    "        'purple': (128, 0, 128),\n",
    "        'violet': (238, 130, 238),\n",
    "        'indigo': (75, 0, 130),\n",
    "        'grey': (128, 128, 128),\n",
    "        'green': (0, 128, 0),\n",
    "        'blue': (0, 0, 255),\n",
    "        'black': (0, 0, 0),\n",
    "        'white': (255, 255, 255),\n",
    "        'cyan': (0, 255, 255),\n",
    "        'magenta': (255, 0, 255),\n",
    "        'turquoise': (64, 224, 208),\n",
    "        'gold': (255, 215, 0),\n",
    "        'silver': (192, 192, 192),\n",
    "        'bronze': (205, 127, 50),\n",
    "        'beige': (245, 245, 220),\n",
    "        'teal': (0, 128, 128),\n",
    "        'maroon': (128, 0, 0),\n",
    "        'olive': (128, 128, 0),\n",
    "        'navy': (0, 0, 128),\n",
    "        'coral': (255, 127, 80),\n",
    "        'salmon': (250, 128, 114),\n",
    "        'khaki': (240, 230, 140),\n",
    "        'lavender': (230, 230, 250),\n",
    "        'peach': (255, 218, 185),\n",
    "        'mint': (189, 252, 201),\n",
    "        'apricot': (251, 206, 177),\n",
    "        'mustard': (255, 219, 88),\n",
    "        'chartreuse': (127, 255, 0),\n",
    "        'taupe': (72, 60, 50),\n",
    "        'lilac': (200, 162, 200),\n",
    "        # Add more colors as needed\n",
    "    }\n",
    "    color_name = \"unknown\"\n",
    "    min_distance = float('inf')\n",
    "    for name, color_rgb in colors.items():\n",
    "        distance = sum((s - q) ** 2 for s, q in zip(rgb, color_rgb))  # Euclidean distance\n",
    "        if distance <= min_distance:\n",
    "            min_distance = distance\n",
    "            color_name = name\n",
    "    return color_name\n",
    "\n",
    "def box_cxcywh_to_xyxy(x):\n",
    "    x_c, y_c, w, h = x.unbind(1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
    "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=1)\n",
    "\n",
    "def rescale_bboxes(out_bbox, size):\n",
    "    img_w, img_h = size\n",
    "    b = box_cxcywh_to_xyxy(out_bbox)\n",
    "    b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32)\n",
    "    return b\n",
    "\n",
    "def save_segmented_parts(image, outputs, threshold=0.8, output_dir='segmented_parts'):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    to_be_ignored = ['sleeve', 'collar', 'pocket', 'neckline', 'buckle', 'zipper', 'applique',\n",
    "                     'bead', 'bow', 'flower', 'fringe', 'ribbon', 'rivet', 'ruffle',\n",
    "                     'sequin', 'tassel']\n",
    "\n",
    "    probas = outputs.logits.softmax(-1)[0, :, :-1]\n",
    "    keep = probas.max(-1).values > threshold\n",
    "    bboxes_scaled = rescale_bboxes(outputs.pred_boxes[0, keep].cpu(), image.size)\n",
    "\n",
    "    for i, (p, box) in enumerate(zip(probas[keep], bboxes_scaled)):\n",
    "        category = idx_to_text(p.argmax())\n",
    "        if category in to_be_ignored:\n",
    "            continue\n",
    "        xmin, ymin, xmax, ymax = box.int().tolist()\n",
    "        cropped_image = image.crop((xmin, ymin, xmax, ymax))\n",
    "\n",
    "        dominant_color = get_dominant_color(cropped_image)\n",
    "        color_name = rgb_to_color_name(dominant_color)  # Convert RGB to color name\n",
    "\n",
    "        cropped_image.save(f\"{output_dir}/{category}_{color_name}_{i}.jpg\")\n",
    "\n",
    "def suggest_outfit(event, dress_string):\n",
    "    # Assuming `openai` is already configured with your API key\n",
    "    # Split the dress_string into a list\n",
    "    clothes_list = dress_string.split(',')\n",
    "    \n",
    "    # Construct a detailed prompt for GPT-4\n",
    "    prompt = (\n",
    "        f\"I have the following items in my wardrobe: {', '.join(clothes_list)}. \"\n",
    "        f\"I am attending {event}. Based on these items, \"\n",
    "        \"what would be the perfect outfit combination for the event? \"\n",
    "        \"Provide a suggestion with a description, followed by '--TDTM--' and \"\n",
    "        \"a structured JSON detailing each item of the outfit.\"\n",
    "        \"reduce the main message to 300 tokens.\"\n",
    "    )\n",
    "    \n",
    "    # Get the completion from GPT-4\n",
    "    completion = client.chat.completions.create(\n",
    "    model =  \"gpt-4-turbo-preview\",\n",
    "    messages= [\n",
    "        {\"role\": \"system\",\"content\": \"You are a fashion assistant.\"},\n",
    "        { \"role\": \"user\",\"content\": prompt}\n",
    "            ],\n",
    "        \n",
    "    max_tokens = 300\n",
    "    )\n",
    "    # print(completion)\n",
    "    response = completion.choices[0].message.content\n",
    "    \n",
    "    # Split the response into the description and JSON parts\n",
    "    description, json_string = response.split('--TDTM--')\n",
    "    \n",
    "    # Parse the JSON part of the response\n",
    "    json_part = '\\n'.join(line for line in json_string.split('\\n') if line.strip() and not line.strip().startswith('```'))\n",
    "    outfit_suggestion = json.loads(json_part)\n",
    "    \n",
    "    # Construct the final response\n",
    "    result = {\n",
    "        \"description\": description.strip(),\n",
    "        \"outfit_suggestion\": outfit_suggestion\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "MODEL_NAME = \"valentinafeve/yolos-fashionpedia\"\n",
    "feature_extractor = YolosFeatureExtractor.from_pretrained('hustvl/yolos-small')\n",
    "model = YolosForObjectDetection.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userA_clothes/test1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:10<00:50, 10.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userA_clothes/test2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:19<00:38,  9.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userA_clothes/test3.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:28<00:27,  9.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userA_clothes/test4.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:36<00:17,  8.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userA_clothes/test5.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:45<00:09,  9.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userA_clothes/test6.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:57<00:00,  9.54s/it]\n"
     ]
    }
   ],
   "source": [
    "image_dir = \"userA_clothes/\"\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "for i in os.listdir(image_dir):\n",
    "    images_path = image_dir + i\n",
    "    print(images_path)\n",
    "    image_name = images_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    image = Image.open(open(images_path, \"rb\"))\n",
    "    image = fix_channels(ToTensor()(image))\n",
    "    image = image.resize((600, 800))\n",
    "    inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # Call the modified function to save segmented parts\n",
    "    save_segmented_parts(image, outputs, threshold=0.8, output_dir=f\"segmented_parts_{image_dir}\")\n",
    "\n",
    "    # img = Image.open(images_path + i)\n",
    "    # img = fix_channels(ToTensor()(img))\n",
    "    # img = img.resize((600, 800))\n",
    "    # features = feature_extractor(img.(0))\n",
    "    # outputs = model(img.unsqueeze(0))\n",
    "    # for i in range(len(outputs[0]['labels'])):\n",
    "    #     print(idx_to_text(outputs[0]['labels'][i].item()), outputs[0]['scores'][i].item())\n",
    "    #     plt.imshow(img)\n",
    "    #     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "annotated_dir = 'segmented_parts_userA_clothes'\n",
    "file_names = []\n",
    "for file in os.listdir(annotated_dir):\n",
    "    file_name = file.split(\".jpg\")[0]\n",
    "    file_name = file_name.replace(\",\", \" \")\n",
    "    file_name = file_name.replace(\"_\", \" \")\n",
    "\n",
    "    file_name = ''.join([i for i in file_name if not i.isdigit()])\n",
    "    file_names.append(file_name)\n",
    "\n",
    "dress_string = ', '.join(file_names)\n",
    "# print(concatenated_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_list = [\n",
    "    'wedding', 'birthday', 'party', 'meeting', 'date', 'casual', 'formal', 'interview', 'work', 'funeral', 'graduation', 'prom', 'concert', 'clubbing', 'beach', 'picnic', 'sport', 'gym', 'travel', 'religious', 'other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "random_event = event_list[int(random() * len(event_list))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8r2AP1tnVQ0FD0Ux9ASc5FpwHXoEd', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='For an interview, maintaining a professional appearance is key. You can wear the taupe pants, which are neutral and formal. Pair these pants with the silver blouse for a touch of professionalism. The silver shoes will match the blouse, creating a cohesive look. To complete the outfit, carry the apricot wallet for a subtle pop of color. This combination ensures you look polished and professional.\\n\\n--TDTM--\\n\\n```json\\n{\\n  \"outfit\": [\\n    {\"item_type\": \"pants\", \"color\": \"taupe\"},\\n    {\"item_type\": \"shirt_blouse\", \"color\": \"silver\"},\\n    {\"item_type\": \"shoe\", \"color\": \"silver\"},\\n    {\"item_type\": \"wallet\", \"color\": \"apricot\"}\\n  ]\\n}\\n```', role='assistant', function_call=None, tool_calls=None))], created=1707650405, model='gpt-4-0125-preview', object='chat.completion', system_fingerprint='fp_f084bcfc79', usage=CompletionUsage(completion_tokens=158, prompt_tokens=125, total_tokens=283))\n"
     ]
    }
   ],
   "source": [
    "suggestion = suggest_outfit(random_event, dress_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For an interview, maintaining a professional appearance is key. You can wear the taupe pants, which are neutral and formal. Pair these pants with the silver blouse for a touch of professionalism. The silver shoes will match the blouse, creating a cohesive look. To complete the outfit, carry the apricot wallet for a subtle pop of color. This combination ensures you look polished and professional.\n"
     ]
    }
   ],
   "source": [
    "print(suggestion['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pants taupe \n",
      "shirt_blouse silver \n",
      "shoe silver \n",
      "wallet apricot \n"
     ]
    }
   ],
   "source": [
    "for i in suggestion['outfit_suggestion']['outfit']:\n",
    "    # print(i)\n",
    "    for k,v in i.items():\n",
    "        print(v,end=\" \")\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
